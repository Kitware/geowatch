data:
  time_steps: 5
  chip_dims: 128
  # channels: "(WV):blue|green|red"
  channels: "blue|green|red"
  window_space_scale: 3GSD
  input_space_scale: 3GSD
  output_space_scale: 3GSD
  batch_size: 8
  chip_overlap: 0
  dist_weights: 0
  min_spacetime_weight: 0.5
  neg_to_pos_ratio: 0.25
  normalize_inputs: true
  normalize_perframe: false
  resample_invalid_frames: true
  temporal_dropout: 0.
  time_sampling: hardish3
  time_span: 5y
  upweight_centers: true
  use_centered_positives: false
  use_grid_positives: true
  verbose: 1
  max_epoch_length: 3200
  mask_low_quality: true
model:
  class_path: watch.tasks.fusion.methods.HeterogeneousModel
  init_args:
    token_width: 8
    token_dim: 64
    position_encoder:
      class_path: watch.tasks.fusion.methods.heterogeneous.MipNerfPositionalEncoder
      init_args:
        in_dims: 3
        max_freq: 3
        num_freqs: 16
    backbone:
      class_path: watch.tasks.fusion.architectures.transformer.TransformerEncoderDecoder
      init_args:
        encoder_depth: 6
        decoder_depth: 1
        dim: 160
        queries_dim: 96
        logits_dim: 64
        latent_dim_head: 256
    spatial_scale_base: 1.0
    temporal_scale_base: 1.0
    global_change_weight: 0.0
    global_class_weight: 0.0
    global_saliency_weight: 1.0
    saliency_loss: focal
    decoder: simple_conv
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 1e-4
    weight_decay: 0.1
    betas:
      - 0.9
      - 0.98
    eps: 1e-12
lr_scheduler:
  class_path: torch.optim.lr_scheduler.OneCycleLR
  init_args:
    max_lr: 0.001
    total_steps: 50000
    anneal_strategy: "linear"
    pct_start: 0.5
profile: false
seed_everything: 1234
trainer:
  accumulate_grad_batches: 32
  callbacks:
    # - class_path: watch.utils.lightning_ext.callbacks.AutoResumer
    # - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    #   init_args:
    #     monitor: val_class_f1_macro
    #     mode: max
    #     save_top_k: 5
    #     auto_insert_metric_name: true
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        mode: min
        save_top_k: 5
        auto_insert_metric_name: true
  check_val_every_n_epoch: 1
  enable_checkpointing: true
  enable_model_summary: true
  enable_progress_bar: true
  # gradient_clip_algorithm: norm
  # gradient_clip_val: 0.5
  log_every_n_steps: 5
  logger: true
  max_steps: 50000
  num_sanity_val_steps: 2
  replace_sampler_ddp: true
  track_grad_norm: 2
