model:
  class_path: watch.tasks.fusion.methods.HeterogeneousModel
  init_args:
    tokenizer: resnet18
    token_dim: 16
    position_encoding_frequencies: 16
    backbone_encoder_depth: 1
    spatial_scale_base: 1.0
    temporal_scale_base: 1.0
    ignore_scale: false
data:
  num_workers: 8
  batch_size: 16
  time_steps: 2
  channels: B02|B03|B04|B08,B01,B11|B12
  chip_overlap: 0.2
  chip_size: 256
  dist_weights: 0
  exclude_sensors: null
  ignore_dilate: 0
  input_space_scale: native
  output_space_scale: null
  window_space_scale: null
  min_spacetime_weight: 0.5
  neg_to_pos_ratio: 0.25
  normalize_inputs: true
  normalize_perframe: false
  resample_invalid_frames: true
  temporal_dropout: 0.0
  time_sampling: contiguous
  time_span: 2y
  torch_sharing_strategy: default
  torch_start_method: default
  upweight_centers: true
  use_centered_positives: false
  use_cloudmask: 1
  use_grid_positives: true
  verbose: 1
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1e-4
    weight_decay: 0
profile: false
seed_everything: true
trainer:
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_class_f1_macro
        save_top_k: 10
        mode: max
  check_val_every_n_epoch: 5
  enable_checkpointing: true
  enable_model_summary: true
  enable_progress_bar: true
  gradient_clip_algorithm: null
  gradient_clip_val: null
  log_every_n_steps: 50
  logger: true
  max_steps: 200000
  num_sanity_val_steps: 2
  replace_sampler_ddp: true
  track_grad_norm: 2
